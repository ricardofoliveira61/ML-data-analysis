{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout, BatchNormalization, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from rdkit import Chem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/Users/utilizador/Desktop/ML-data-analysis-main/random_samples_final.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples=pd.read_pickle(filepath_or_buffer= path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 148)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = random_samples['Y']\n",
    "input= random_samples[['morgan_fingerprints', 'Gene_expression']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(input, output, test_size=0.4, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_drugs = x_train.filter(regex='morgan', axis=1)\n",
    "x_train_cell_lines = x_train.iloc[:, x_train.columns.get_loc('morgan_fingerprints') + 1:]\n",
    "\n",
    "x_val_drugs = x_val.filter(regex='morgan', axis=1)\n",
    "x_val_cell_lines = x_val.iloc[:, x_val.columns.get_loc('morgan_fingerprints') + 1:]\n",
    "\n",
    "x_test_drugs = x_test.filter(regex='morgan', axis=1)\n",
    "x_test_cell_lines = x_test.iloc[:, x_test.columns.get_loc('morgan_fingerprints') + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_drugs = pd.concat([x_train_drugs.drop(['morgan_fingerprints'], axis=1), x_train_drugs['morgan_fingerprints'].apply(lambda x: pd.Series({f'fp{str(i)}': val for i, val in enumerate(x)}))], axis=1)\n",
    "x_test_drugs = pd.concat([x_test_drugs.drop(['morgan_fingerprints'], axis=1), x_test_drugs['morgan_fingerprints'].apply(lambda x: pd.Series({f'fp{str(i)}': val for i, val in enumerate(x)}))], axis=1)\n",
    "x_val_drugs = pd.concat([x_val_drugs.drop(['morgan_fingerprints'], axis=1), x_val_drugs['morgan_fingerprints'].apply(lambda x: pd.Series({f'fp{str(i)}': val for i, val in enumerate(x)}))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp0</th>\n",
       "      <th>fp1</th>\n",
       "      <th>fp2</th>\n",
       "      <th>fp3</th>\n",
       "      <th>fp4</th>\n",
       "      <th>fp5</th>\n",
       "      <th>fp6</th>\n",
       "      <th>fp7</th>\n",
       "      <th>fp8</th>\n",
       "      <th>fp9</th>\n",
       "      <th>...</th>\n",
       "      <th>fp2038</th>\n",
       "      <th>fp2039</th>\n",
       "      <th>fp2040</th>\n",
       "      <th>fp2041</th>\n",
       "      <th>fp2042</th>\n",
       "      <th>fp2043</th>\n",
       "      <th>fp2044</th>\n",
       "      <th>fp2045</th>\n",
       "      <th>fp2046</th>\n",
       "      <th>fp2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71716</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12619</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149429</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47981</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32449</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fp0  fp1  fp2  fp3  fp4  fp5  fp6  fp7  fp8  fp9  ...  fp2038  fp2039  \\\n",
       "71716     0    0    0    0    0    0    0    0    1    0  ...       0       0   \n",
       "152829    0    0    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "12619     0    1    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "149429    0    1    1    0    0    0    0    0    0    0  ...       0       0   \n",
       "164112    0    0    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...     ...   \n",
       "47981     0    1    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "48999     0    1    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "11139     0    0    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "32449     0    0    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "54008     0    0    0    0    0    0    0    0    0    0  ...       0       0   \n",
       "\n",
       "        fp2040  fp2041  fp2042  fp2043  fp2044  fp2045  fp2046  fp2047  \n",
       "71716        0       0       0       0       0       0       0       0  \n",
       "152829       0       0       0       0       0       0       0       0  \n",
       "12619        0       0       0       0       0       0       0       0  \n",
       "149429       0       0       0       0       0       0       0       0  \n",
       "164112       0       0       0       1       0       0       0       0  \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "47981        0       0       0       0       0       0       0       0  \n",
       "48999        0       0       0       0       0       0       0       0  \n",
       "11139        0       0       0       0       0       0       0       0  \n",
       "32449        0       0       0       0       0       0       0       0  \n",
       "54008        0       0       0       0       1       0       0       0  \n",
       "\n",
       "[6000 rows x 2048 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cell = x_train_cell_lines['Gene_expression'].apply(pd.Series)\n",
    "x_train_cell.columns = [f'gene_{i}' for i in range(x_train_cell.shape[1])]\n",
    "x_train_cell_lines = pd.concat([x_train_cell_lines.drop(columns=['Gene_expression']), x_train_cell], axis=1)\n",
    "\n",
    "#####\n",
    "x_test_cell = x_test_cell_lines['Gene_expression'].apply(pd.Series)\n",
    "x_test_cell.columns = [f'gene_{i}' for i in range(x_test_cell.shape[1])]\n",
    "x_test_cell_lines = pd.concat([x_test_cell_lines.drop(columns=['Gene_expression']), x_test_cell], axis=1)\n",
    "\n",
    "#####\n",
    "x_val_cell = x_val_cell_lines['Gene_expression'].apply(pd.Series)\n",
    "x_val_cell.columns = [f'gene_{i}' for i in range(x_val_cell.shape[1])]\n",
    "x_val_cell_lines = pd.concat([x_val_cell_lines.drop(columns=['Gene_expression']), x_val_cell], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_13339</th>\n",
       "      <th>gene_13340</th>\n",
       "      <th>gene_13341</th>\n",
       "      <th>gene_13342</th>\n",
       "      <th>gene_13343</th>\n",
       "      <th>gene_13344</th>\n",
       "      <th>gene_13345</th>\n",
       "      <th>gene_13346</th>\n",
       "      <th>gene_13347</th>\n",
       "      <th>gene_13348</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71716</th>\n",
       "      <td>7.188877</td>\n",
       "      <td>8.928756</td>\n",
       "      <td>4.663555</td>\n",
       "      <td>3.416280</td>\n",
       "      <td>3.096305</td>\n",
       "      <td>6.826444</td>\n",
       "      <td>3.323095</td>\n",
       "      <td>5.147193</td>\n",
       "      <td>6.679149</td>\n",
       "      <td>3.238289</td>\n",
       "      <td>...</td>\n",
       "      <td>3.235135</td>\n",
       "      <td>4.905903</td>\n",
       "      <td>4.098310</td>\n",
       "      <td>2.811946</td>\n",
       "      <td>5.429300</td>\n",
       "      <td>2.770339</td>\n",
       "      <td>8.937286</td>\n",
       "      <td>2.599858</td>\n",
       "      <td>9.414679</td>\n",
       "      <td>7.273168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152829</th>\n",
       "      <td>6.629262</td>\n",
       "      <td>9.313841</td>\n",
       "      <td>3.961542</td>\n",
       "      <td>3.407503</td>\n",
       "      <td>3.027680</td>\n",
       "      <td>6.590986</td>\n",
       "      <td>8.095744</td>\n",
       "      <td>7.727150</td>\n",
       "      <td>6.079737</td>\n",
       "      <td>3.240734</td>\n",
       "      <td>...</td>\n",
       "      <td>3.320698</td>\n",
       "      <td>4.280165</td>\n",
       "      <td>4.017937</td>\n",
       "      <td>2.634867</td>\n",
       "      <td>5.302352</td>\n",
       "      <td>3.331810</td>\n",
       "      <td>8.152317</td>\n",
       "      <td>3.389978</td>\n",
       "      <td>9.206188</td>\n",
       "      <td>7.482943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12619</th>\n",
       "      <td>3.454855</td>\n",
       "      <td>9.246209</td>\n",
       "      <td>4.628587</td>\n",
       "      <td>4.432062</td>\n",
       "      <td>3.354918</td>\n",
       "      <td>3.255320</td>\n",
       "      <td>6.697093</td>\n",
       "      <td>5.299671</td>\n",
       "      <td>5.436861</td>\n",
       "      <td>3.538260</td>\n",
       "      <td>...</td>\n",
       "      <td>3.474007</td>\n",
       "      <td>4.141157</td>\n",
       "      <td>4.737547</td>\n",
       "      <td>2.636211</td>\n",
       "      <td>3.529433</td>\n",
       "      <td>3.240956</td>\n",
       "      <td>9.338429</td>\n",
       "      <td>9.267335</td>\n",
       "      <td>8.664311</td>\n",
       "      <td>8.074440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149429</th>\n",
       "      <td>8.072295</td>\n",
       "      <td>9.169414</td>\n",
       "      <td>3.702357</td>\n",
       "      <td>3.329170</td>\n",
       "      <td>3.034988</td>\n",
       "      <td>4.603880</td>\n",
       "      <td>8.439930</td>\n",
       "      <td>8.285421</td>\n",
       "      <td>4.541539</td>\n",
       "      <td>3.426734</td>\n",
       "      <td>...</td>\n",
       "      <td>3.739961</td>\n",
       "      <td>4.688540</td>\n",
       "      <td>3.064446</td>\n",
       "      <td>2.681717</td>\n",
       "      <td>4.279433</td>\n",
       "      <td>2.920413</td>\n",
       "      <td>8.477269</td>\n",
       "      <td>3.314085</td>\n",
       "      <td>9.177474</td>\n",
       "      <td>7.965078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164112</th>\n",
       "      <td>9.241336</td>\n",
       "      <td>9.865577</td>\n",
       "      <td>3.932945</td>\n",
       "      <td>3.688377</td>\n",
       "      <td>3.240228</td>\n",
       "      <td>5.724733</td>\n",
       "      <td>9.110355</td>\n",
       "      <td>5.433205</td>\n",
       "      <td>5.685882</td>\n",
       "      <td>3.340002</td>\n",
       "      <td>...</td>\n",
       "      <td>3.244485</td>\n",
       "      <td>4.215788</td>\n",
       "      <td>3.566160</td>\n",
       "      <td>2.619875</td>\n",
       "      <td>4.485273</td>\n",
       "      <td>3.121554</td>\n",
       "      <td>8.716633</td>\n",
       "      <td>3.061928</td>\n",
       "      <td>9.722662</td>\n",
       "      <td>6.754493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47981</th>\n",
       "      <td>5.051663</td>\n",
       "      <td>9.024239</td>\n",
       "      <td>4.196993</td>\n",
       "      <td>3.726976</td>\n",
       "      <td>3.267616</td>\n",
       "      <td>3.389011</td>\n",
       "      <td>6.646962</td>\n",
       "      <td>5.949845</td>\n",
       "      <td>5.393282</td>\n",
       "      <td>3.981700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.004081</td>\n",
       "      <td>4.765050</td>\n",
       "      <td>3.968262</td>\n",
       "      <td>2.657251</td>\n",
       "      <td>3.338593</td>\n",
       "      <td>3.107874</td>\n",
       "      <td>8.656260</td>\n",
       "      <td>2.720959</td>\n",
       "      <td>8.986667</td>\n",
       "      <td>8.070330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48999</th>\n",
       "      <td>3.303111</td>\n",
       "      <td>10.344945</td>\n",
       "      <td>6.027395</td>\n",
       "      <td>3.439446</td>\n",
       "      <td>4.974175</td>\n",
       "      <td>3.269596</td>\n",
       "      <td>7.853677</td>\n",
       "      <td>5.432638</td>\n",
       "      <td>5.932224</td>\n",
       "      <td>3.683839</td>\n",
       "      <td>...</td>\n",
       "      <td>3.185001</td>\n",
       "      <td>3.562078</td>\n",
       "      <td>5.118068</td>\n",
       "      <td>2.671580</td>\n",
       "      <td>5.755938</td>\n",
       "      <td>3.181971</td>\n",
       "      <td>8.000509</td>\n",
       "      <td>3.078481</td>\n",
       "      <td>9.206829</td>\n",
       "      <td>8.991101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>3.363446</td>\n",
       "      <td>9.604299</td>\n",
       "      <td>3.931429</td>\n",
       "      <td>3.835969</td>\n",
       "      <td>3.216174</td>\n",
       "      <td>4.528885</td>\n",
       "      <td>3.272706</td>\n",
       "      <td>6.099419</td>\n",
       "      <td>5.824356</td>\n",
       "      <td>3.635076</td>\n",
       "      <td>...</td>\n",
       "      <td>4.028962</td>\n",
       "      <td>4.106226</td>\n",
       "      <td>4.059121</td>\n",
       "      <td>2.602437</td>\n",
       "      <td>4.653821</td>\n",
       "      <td>3.083361</td>\n",
       "      <td>8.595628</td>\n",
       "      <td>6.496206</td>\n",
       "      <td>9.026961</td>\n",
       "      <td>7.325749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32449</th>\n",
       "      <td>7.646055</td>\n",
       "      <td>9.467647</td>\n",
       "      <td>4.024392</td>\n",
       "      <td>3.400185</td>\n",
       "      <td>3.406030</td>\n",
       "      <td>9.578489</td>\n",
       "      <td>7.716921</td>\n",
       "      <td>6.283608</td>\n",
       "      <td>4.776286</td>\n",
       "      <td>3.580554</td>\n",
       "      <td>...</td>\n",
       "      <td>3.187405</td>\n",
       "      <td>4.545189</td>\n",
       "      <td>3.256456</td>\n",
       "      <td>2.576372</td>\n",
       "      <td>4.336076</td>\n",
       "      <td>2.948622</td>\n",
       "      <td>8.031265</td>\n",
       "      <td>3.333082</td>\n",
       "      <td>8.756423</td>\n",
       "      <td>7.684665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54008</th>\n",
       "      <td>7.689987</td>\n",
       "      <td>10.118531</td>\n",
       "      <td>3.807904</td>\n",
       "      <td>3.427905</td>\n",
       "      <td>3.425122</td>\n",
       "      <td>3.037615</td>\n",
       "      <td>8.163557</td>\n",
       "      <td>5.168350</td>\n",
       "      <td>4.271657</td>\n",
       "      <td>3.642759</td>\n",
       "      <td>...</td>\n",
       "      <td>3.502290</td>\n",
       "      <td>4.443307</td>\n",
       "      <td>3.819817</td>\n",
       "      <td>2.644480</td>\n",
       "      <td>4.082617</td>\n",
       "      <td>3.507859</td>\n",
       "      <td>7.816005</td>\n",
       "      <td>3.726281</td>\n",
       "      <td>9.067021</td>\n",
       "      <td>6.269357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 13349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gene_0     gene_1    gene_2    gene_3    gene_4    gene_5    gene_6  \\\n",
       "71716   7.188877   8.928756  4.663555  3.416280  3.096305  6.826444  3.323095   \n",
       "152829  6.629262   9.313841  3.961542  3.407503  3.027680  6.590986  8.095744   \n",
       "12619   3.454855   9.246209  4.628587  4.432062  3.354918  3.255320  6.697093   \n",
       "149429  8.072295   9.169414  3.702357  3.329170  3.034988  4.603880  8.439930   \n",
       "164112  9.241336   9.865577  3.932945  3.688377  3.240228  5.724733  9.110355   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "47981   5.051663   9.024239  4.196993  3.726976  3.267616  3.389011  6.646962   \n",
       "48999   3.303111  10.344945  6.027395  3.439446  4.974175  3.269596  7.853677   \n",
       "11139   3.363446   9.604299  3.931429  3.835969  3.216174  4.528885  3.272706   \n",
       "32449   7.646055   9.467647  4.024392  3.400185  3.406030  9.578489  7.716921   \n",
       "54008   7.689987  10.118531  3.807904  3.427905  3.425122  3.037615  8.163557   \n",
       "\n",
       "          gene_7    gene_8    gene_9  ...  gene_13339  gene_13340  gene_13341  \\\n",
       "71716   5.147193  6.679149  3.238289  ...    3.235135    4.905903    4.098310   \n",
       "152829  7.727150  6.079737  3.240734  ...    3.320698    4.280165    4.017937   \n",
       "12619   5.299671  5.436861  3.538260  ...    3.474007    4.141157    4.737547   \n",
       "149429  8.285421  4.541539  3.426734  ...    3.739961    4.688540    3.064446   \n",
       "164112  5.433205  5.685882  3.340002  ...    3.244485    4.215788    3.566160   \n",
       "...          ...       ...       ...  ...         ...         ...         ...   \n",
       "47981   5.949845  5.393282  3.981700  ...    3.004081    4.765050    3.968262   \n",
       "48999   5.432638  5.932224  3.683839  ...    3.185001    3.562078    5.118068   \n",
       "11139   6.099419  5.824356  3.635076  ...    4.028962    4.106226    4.059121   \n",
       "32449   6.283608  4.776286  3.580554  ...    3.187405    4.545189    3.256456   \n",
       "54008   5.168350  4.271657  3.642759  ...    3.502290    4.443307    3.819817   \n",
       "\n",
       "        gene_13342  gene_13343  gene_13344  gene_13345  gene_13346  \\\n",
       "71716     2.811946    5.429300    2.770339    8.937286    2.599858   \n",
       "152829    2.634867    5.302352    3.331810    8.152317    3.389978   \n",
       "12619     2.636211    3.529433    3.240956    9.338429    9.267335   \n",
       "149429    2.681717    4.279433    2.920413    8.477269    3.314085   \n",
       "164112    2.619875    4.485273    3.121554    8.716633    3.061928   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "47981     2.657251    3.338593    3.107874    8.656260    2.720959   \n",
       "48999     2.671580    5.755938    3.181971    8.000509    3.078481   \n",
       "11139     2.602437    4.653821    3.083361    8.595628    6.496206   \n",
       "32449     2.576372    4.336076    2.948622    8.031265    3.333082   \n",
       "54008     2.644480    4.082617    3.507859    7.816005    3.726281   \n",
       "\n",
       "        gene_13347  gene_13348  \n",
       "71716     9.414679    7.273168  \n",
       "152829    9.206188    7.482943  \n",
       "12619     8.664311    8.074440  \n",
       "149429    9.177474    7.965078  \n",
       "164112    9.722662    6.754493  \n",
       "...            ...         ...  \n",
       "47981     8.986667    8.070330  \n",
       "48999     9.206829    8.991101  \n",
       "11139     9.026961    7.325749  \n",
       "32449     8.756423    7.684665  \n",
       "54008     9.067021    6.269357  \n",
       "\n",
       "[6000 rows x 13349 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cell_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 2048), (6000, 13349), (6000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_drugs.shape, x_train_cell_lines.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2048), (2000, 13349), (2000,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_drugs.shape, x_test_cell_lines.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2048), (2000, 13349), (2000,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_drugs.shape, x_val_cell_lines.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71716    -1.050204\n",
       "152829    1.140108\n",
       "12619     4.773284\n",
       "149429    2.032094\n",
       "164112    4.692048\n",
       "            ...   \n",
       "47981     3.856404\n",
       "48999     1.494062\n",
       "11139     3.466243\n",
       "32449     2.484426\n",
       "54008     3.507105\n",
       "Name: Y, Length: 6000, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4468      0.515744\n",
       "73063     3.724621\n",
       "78403     5.581613\n",
       "114638   -1.723433\n",
       "142341   -1.488753\n",
       "            ...   \n",
       "151943   -3.099915\n",
       "8219      3.981576\n",
       "155396    1.500072\n",
       "27332     1.022270\n",
       "107440    0.761226\n",
       "Name: Y, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de y_train: <class 'pandas.core.series.Series'>\n",
      "Dtype de y_train: float64\n",
      "Exemplo de y_train: 71716    -1.050204\n",
      "152829    1.140108\n",
      "12619     4.773284\n",
      "149429    2.032094\n",
      "164112    4.692048\n",
      "Name: Y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipo de y_train:\", type(y_train))\n",
    "print(\"Dtype de y_train:\", y_train.dtype)\n",
    "print(\"Exemplo de y_train:\", y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 13349)\n",
      "(6000, 2048)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cell_lines.shape)\n",
    "print(x_train_drugs.shape)\n",
    "\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cell_line_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13349</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drug_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">133,500</span> │ cell_line_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> │ drug_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_concat  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,000</span> │ input_layer_conc… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ic50_prediction_de… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ cell_line_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13349\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drug_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │    \u001b[38;5;34m133,500\u001b[0m │ cell_line_input[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │     \u001b[38;5;34m20,490\u001b[0m │ drug_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m40\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m40\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_concat  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │     \u001b[38;5;34m21,000\u001b[0m │ input_layer_conc… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │      \u001b[38;5;34m4,000\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ic50_prediction_de… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │      \u001b[38;5;34m1,001\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,071</span> (703.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m180,071\u001b[0m (703.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,031</span> (695.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m178,031\u001b[0m (695.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,040</span> (7.97 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,040\u001b[0m (7.97 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected float32, but got ic50_prediction_dense_output of type 'str'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m DenseModel(x_train_cell_lines\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], x_train_drugs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],expr_hlayers_sizes\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[625, 312]\u001b[39m\u001b[39m'\u001b[39m, drug_hlayers_sizes\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[1000, 500, 250]\u001b[39m\u001b[39m'\u001b[39m,predictor_hlayers_sizes\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[1000]\u001b[39m\u001b[39m'\u001b[39m, hidden_dropout\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m, learn_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[0;32m----> 6\u001b[0m model\u001b[39m.\u001b[39;49mtrain(x_train_cell_lines, x_train_drugs, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m126\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m val_loss, val_mae \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_val_cell_lines, x_val_drugs, y_val)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m}\u001b[39;00m\u001b[39m, Test MAE: \u001b[39m\u001b[39m{\u001b[39;00mval_mae\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ML-data-analysis-main/Deep_learning_completo/models.py:112\u001b[0m, in \u001b[0;36mDenseModel.train\u001b[0;34m(self, cell_line_train_data, drug_train_data, train_labels, epochs, batch_size)\u001b[0m\n\u001b[1;32m    109\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    110\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39m../trained_models/dense_model.keras\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    113\u001b[0m     {\u001b[39m'\u001b[39;49m\u001b[39mcell_line_input\u001b[39;49m\u001b[39m'\u001b[39;49m: cell_line_train_data, \u001b[39m'\u001b[39;49m\u001b[39mdrug_input\u001b[39;49m\u001b[39m'\u001b[39;49m: drug_train_data},\n\u001b[1;32m    114\u001b[0m     {\u001b[39m'\u001b[39;49m\u001b[39mic50_prediction_dense_output\u001b[39;49m\u001b[39m'\u001b[39;49m: train_labels},\n\u001b[1;32m    115\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    116\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    117\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m    118\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping, model_checkpoint]\n\u001b[1;32m    119\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sib_tb/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sib_tb/lib/python3.9/site-packages/optree/ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m leaves, treespec \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    765\u001b[0m flat_args \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treespec\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rests]\n\u001b[0;32m--> 766\u001b[0m \u001b[39mreturn\u001b[39;00m treespec\u001b[39m.\u001b[39;49munflatten(\u001b[39mmap\u001b[39;49m(func, \u001b[39m*\u001b[39;49mflat_args))\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected float32, but got ic50_prediction_dense_output of type 'str'."
     ]
    }
   ],
   "source": [
    "from models import DenseModel\n",
    "\n",
    "model = DenseModel(x_train_cell_lines.shape[1], x_train_drugs.shape[1],expr_hlayers_sizes='[625, 312]', drug_hlayers_sizes='[1000, 500, 250]',predictor_hlayers_sizes='[1000]', hidden_dropout=0.3, optimizer='Adam', learn_rate=0.0001)\n",
    "print(model.summary())\n",
    "\n",
    "model.train(x_train_cell_lines, x_train_drugs, y_train, epochs=100, batch_size=126)\n",
    "\n",
    "val_loss, val_mae = model.evaluate(x_val_cell_lines, x_val_drugs, y_val)\n",
    "print(f'Test Loss: {val_loss}, Test MAE: {val_mae}')\n",
    "\n",
    "predictions = model.predict(x_test_cell_lines, x_test_drugs)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss and mae from training and validation data side by side\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(model.history.history['loss'], label='train')\n",
    "# plt.plot(model.history.history['val_loss'], label='validation')\n",
    "# plt.title('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(model.history.history['mae'], label='train')\n",
    "# plt.plot(model.history.history['val_mae'], label='validation')\n",
    "# plt.title('MAE')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# print('Dense model')\n",
    "# print('MAE: ', mean_absolute_error(y_test, predictions))\n",
    "# print('MSE: ', mean_squared_error(y_test, predictions))\n",
    "# print('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "# print('R2: ', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gat = random_samples['Y']\n",
    "input_gat= random_samples[['SMILES', 'Gene_expression']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(input_gat, output_gat, test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_drugs = x_train.filter(regex='SMILES', axis=1)\n",
    "x_train_cell_lines = x_train.iloc[:, x_train.columns.get_loc('SMILES') + 1:]\n",
    "\n",
    "x_val_drugs = x_val.filter(regex='SMILES', axis=1)\n",
    "x_val_cell_lines = x_val.iloc[:, x_val.columns.get_loc('SMILES') + 1:]\n",
    "\n",
    "x_test_drugs = x_test.filter(regex='SMILES', axis=1)\n",
    "x_test_cell_lines = x_test.iloc[:, x_test.columns.get_loc('SMILES') + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configurar Pandas para exibir todas as linhas\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Exibir a série completa\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphfeaturizer import GraphFeaturizer\n",
    "\n",
    "featurizer_train = GraphFeaturizer()\n",
    "node_features_train, adjacency_matrix_train = featurizer_train.featurize_df(x_train_drugs, 'SMILES')\n",
    "\n",
    "featurizer_val = GraphFeaturizer()\n",
    "node_features_val, adjacency_matrix_val = featurizer_val.featurize_df(x_val_drugs, 'SMILES')\n",
    "\n",
    "featurizer_test = GraphFeaturizer()\n",
    "node_features_test, adjacency_matrix_test = featurizer_test.featurize_df(x_test_drugs, 'SMILES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forma de node_features_train:\", node_features_train.shape)\n",
    "print(\"Tipo de node_features_train:\", type(node_features_train))\n",
    "\n",
    "print(\"Forma de adjacency_matrix_train:\", adjacency_matrix_train.shape)\n",
    "print(\"Tipo de adjacency_matrix_train:\", type(adjacency_matrix_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Verificar valores nulos ou inválidos\n",
    "print(\"Valores nulos em node_features_train:\", np.isnan(node_features_train).sum())\n",
    "print(\"Valores nulos em adjacency_matrix_train:\", np.isnan(adjacency_matrix_train).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DrugGATModel\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "model = DrugGATModel(expr_dim=x_train_cell_lines.shape[1], expr_hlayers_sizes='[156, 156]', drug_gat_layers='[125, 75]',predictor_hlayers_sizes='[125]', hidden_dropout=0.3, optimizer='Adam', learn_rate=0.0001)\n",
    "print(model.summary())\n",
    "model.train(x_train_cell_lines, node_features_train, adjacency_matrix_train, y_train, epochs=100, batch_size=64)\n",
    "\n",
    "val_loss, val_mae = model.evaluate(x_val_cell_lines, node_features_val, adjacency_matrix_val, y_val)\n",
    "print(f'Test Loss: {val_loss}, Test MAE: {val_mae}')\n",
    "\n",
    "predictions = model.predict(x_test_cell_lines, node_features_test, adjacency_matrix_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss and mae from training and validation data side by side\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model.history.history['loss'], label='train')\n",
    "plt.plot(model.history.history['val_loss'], label='validation')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model.history.history['mae'], label='train')\n",
    "plt.plot(model.history.history['val_mae'], label='validation')\n",
    "plt.title('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "print('GAT model')\n",
    "print('MAE: ', mean_absolute_error(y_test, predictions))\n",
    "print('MSE: ', mean_squared_error(y_test, predictions))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2: ', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sib_tb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
